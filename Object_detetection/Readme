LIDARs are the most important piece of hardware in any self-driving car (with the exception of Tesla) and is very necessary for understanding the environment in 3D. 
They work very similar to a RADAR or a SONAR, except for the fact that they emit light instead of radio or sound waves. The advantage of a LIDAR over any other sensor is :

1) It has a 360 degree field of view.
2) The output of a LIDAR is a set of points in space, called a point cloud.

A typical point cloud consists of four different values (x, y, z and r) corresponding to the x, y and z co-ordinates of the point of which the light ray was reflected off and r being the reflectance.
Now, with 3D positions of each point in the environment, obtained from the LIDAR, the self-driving car can perceive the environment so much better. 
This enables the car to not just see where the object is, but also how far it is from the car and in what direction it is oriented in.
KITTI is one of the best datasets that are available for benchmarking algorithms for 3D object detection. Using the dataset is a bit tricky as the labels in the dataset are not what you think they are.
The dataset needs to be understood really well before converting it into a useful format to use for 3d object detection. The dataset consists mainly of four different kinds of files, namely:

1) camera_2 image (.png)
2) velodyne point cloud (.bin)
3) camera_2 label (.txt)
4) calibration (.txt)
The camera_2 image folder contains the RGB images taken by Cam 2 . 
Each time the x-axis of the LIDAR and the y-axis of Cam 0 line up, the camera takes a picture.
The velodyne folder consists of lidar data in the form of bin files. 
Each bin file consists of data corresponding to 360 degree rotation of the lidar. 
Each point is stored with its (x, y, z) coordinate and an additional reflectance value (r). 
Each bin file consists of approximately 120,000 such points (varies file to file).
